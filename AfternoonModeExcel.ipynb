{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mpFkunbFfPJH"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPitptt0JJ2DntPCJzmGMOS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markhayes0811/Stock/blob/main/AfternoonModeExcel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guide/Definitions:"
      ],
      "metadata": {
        "id": "ZrSqMsL8yFiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Term                       | Meaning                                                                |\n",
        "| -------------------------- | ---------------------------------------------------------------------- |\n",
        "| **Training Set**           | Subset of historical data used to fit the model                        |\n",
        "| **Testing Set**            | Subset held back to test model performance                             |\n",
        "| **Actual Mean Return (%)** | Return from `y_test` during testing                                    |\n",
        "| **Realized Return (%)**    | True return from live market prices, used **after** the market session |\n"
      ],
      "metadata": {
        "id": "27HJ7RKWxhzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§  What Is the Training Set?\n",
        "The training set is the portion of your historical data that the machine learning model uses to learn patterns â€” in your case, how early-morning stock data relates to short-term returns.\n",
        "\n",
        "ðŸ” In Your Notebook Context:\n",
        "1. You fetch intraday stock data from 09:30 to 12:00.\n",
        "\n",
        "2. After feature engineering (e.g. RSI, MACD, VWAP), you:\n",
        "          \n",
        "          in python:\n",
        "          X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
        "                      \n",
        "This splits the data into:\n",
        "\n",
        "X_train, y_train â†’ training set (usually 80%)\n",
        "\n",
        "X_test, y_test â†’ testing set (usually 20%)\n"
      ],
      "metadata": {
        "id": "8v84xe61wk5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Your model (e.g. XGBoost) is trained on:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "4. Then you evaluate on the test set (X_test) to see how well the model generalizes.                       \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "âš ï¸ Clarification:\n",
        "The **Actual Mean Return (%)** in your morning notebook is based on y_test, not real future data.\n",
        "\n",
        "The **Realized Return (%)** in your afternoon notebook is calculated from actual post-market price data â€” itâ€™s what truly happened.\n",
        "\n"
      ],
      "metadata": {
        "id": "LXR0mmREw5jP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\NEHC, HCTI, GNLN, CGTL, CVAC, GTI, SOAR, CGTL, RADX"
      ],
      "metadata": {
        "id": "u6GamuVZPMGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column                        | Description                                                                                      |\n",
        "| ----------------------------- | ------------------------------------------------------------------------------------------------ |\n",
        "| **Predicted Mean Return (%)** | The modelâ€™s predicted average return **(in %)** for a specific interval (e.g., 9:30â€“10:00).      |\n",
        "| **Actual Mean Return (%)**    | The average return observed **in the training set**, not from real post-facto market movement.   |\n",
        "| **Signal**                    | Model-generated trading suggestion: `Buy` if prediction > +0.2%, `Sell` if < -0.2%, else `Hold`. |\n",
        "| **Ticker**                    | The stock ticker symbol the prediction was made for (e.g., `HCTI`, `GTI`, etc).                  |\n",
        "| **Realized Return (%)**       | The **true return from actual price data**, computed by the afternoon script (market-realized).  |\n",
        "| **Abs Error**                 | The absolute difference between predicted and realized returns. Measures accuracy of the model.  |\n",
        "\n",
        "\n",
        "âš ï¸ Important Distinction\n",
        "âœ… Actual Mean Return (%) = what the model trained on and tried to match.\n",
        "\n",
        "âœ… Realized Return (%) = what really happened, used for performance validation in the afternoon session.\n",
        "\n",
        "You ideally want:\n",
        "\n",
        "Predicted Mean Return (%) â‰ˆ Realized Return (%)\n",
        "\n",
        "Abs Error as small as possible"
      ],
      "metadata": {
        "id": "uwebtJVSvknX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "          â”‚ Raw Intraday Data â”‚   (09:30â€“12:00 1-min bars)\n",
        "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                   â”‚\n",
        "                   â–¼\n",
        "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "          â”‚ Feature Engineeringâ”‚   (returns, RSI, MACD, VWAP, etc.)\n",
        "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                   â”‚\n",
        "                   â–¼\n",
        "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "          â”‚ Interval Labeling  â”‚   ('early', 'mid', 'late')\n",
        "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                   â”‚\n",
        "                   â–¼\n",
        "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "      â”‚ Train-Test Split (80/20)   â”‚\n",
        "      â”‚                            â”‚\n",
        "      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
        "      â”‚  â”‚ X_train    â”‚ â”‚ X_test â”‚ â”‚  âž¤ Features\n",
        "      â”‚  â”‚ y_train    â”‚ â”‚ y_test â”‚ â”‚  âž¤ Labels (block returns)\n",
        "      â””â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                   â”‚\n",
        "                   â–¼\n",
        "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "          â”‚ Model Training     â”‚   (XGBoost fit on X_train, y_train)\n",
        "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                   â”‚\n",
        "                   â–¼\n",
        "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "          â”‚ Predict on X_test  â”‚\n",
        "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                   â”‚\n",
        "                   â–¼\n",
        "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "        â”‚ Compare to y_test            â”‚\n",
        "        â”‚ âž¤ Actual Mean Return (%)     â”‚\n",
        "        â”‚ âž¤ Predicted Mean Return (%)  â”‚\n",
        "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                     â”‚\n",
        "                     â–¼\n",
        "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "        â”‚ Save predictions to CSV (morning)  â”‚\n",
        "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                         â”‚\n",
        "                         â–¼\n",
        "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "        â”‚ Fetch new price data (afternoon)   â”‚\n",
        "        â”‚ âž¤ Compute Realized Return (%)      â”‚\n",
        "        â”‚ âž¤ Compute Abs Error                â”‚\n",
        "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "\n",
        "\n",
        "ðŸ” Key Feedback Loops:\n",
        "Morning mode: Predicted vs Test Set (y_test)\n",
        "\n",
        "Afternoon mode: Predicted vs Realized (actual market outcome)"
      ],
      "metadata": {
        "id": "J_K3qDUqxpnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Afternoon Mode.1 - beta (use Mode.2)"
      ],
      "metadata": {
        "id": "mpFkunbFfPJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… MODE TOGGLE\n",
        "mode = 'afternoon'  # Options: 'morning' or 'afternoon'\n",
        "\n",
        "# ðŸ“¦ Install dependencies\n",
        "!pip install pandas matplotlib seaborn scikit-learn xgboost openpyxl --quiet\n",
        "\n",
        "# ðŸ”§ Imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from IPython.display import display, HTML\n",
        "import pytz\n",
        "import os\n",
        "from pathlib import Path\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# âœ… Grid Search Toggle\n",
        "use_grid_search = False\n",
        "\n",
        "# ðŸ—‚ï¸ Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = Path('/content/drive/MyDrive/stock_predictions')\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ðŸŽ¯ Polygon API\n",
        "API_KEY = 'H3nRWzRqnMqojU9y1gkbo1UqTbl2peqf'\n",
        "\n",
        "# ðŸ“ˆ Fetch minute-level data\n",
        "def fetch_minute_data(ticker, date):\n",
        "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/{date}/{date}\"\n",
        "    params = {\"adjusted\": \"true\", \"sort\": \"asc\", \"limit\": 50000, \"apiKey\": API_KEY}\n",
        "    r = requests.get(url, params=params)\n",
        "    if r.status_code != 200:\n",
        "        print(f\"âŒ Error fetching data for {ticker}: {r.text}\")\n",
        "        return None\n",
        "    df = pd.DataFrame(r.json().get(\"results\", []))\n",
        "    if df.empty:\n",
        "        return None\n",
        "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.rename(columns={\"o\": \"open\", \"h\": \"high\", \"l\": \"low\", \"c\": \"close\", \"v\": \"volume\"})\n",
        "    return df[['open', 'high', 'low', 'close', 'volume']]\n",
        "\n",
        "# ðŸ” Evaluate Predictions vs Actuals\n",
        "def evaluate_actual_vs_predicted(pred_path, tickers, date):\n",
        "    full_df = pd.read_csv(pred_path)\n",
        "    all_evals = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        df = fetch_minute_data(ticker, date)\n",
        "        if df is None:\n",
        "            continue\n",
        "\n",
        "        df = df.between_time(\"09:30\", \"12:00\").copy()\n",
        "        df['returns'] = df['close'].pct_change()\n",
        "\n",
        "        df['interval'] = pd.cut(\n",
        "            df.index.hour * 60 + df.index.minute,\n",
        "            bins=[0, 600, 630, 720],\n",
        "            labels=['early (9:30â€“10:00)', 'mid (10:00â€“10:30)', 'late (10:30â€“12:00)']\n",
        "        )\n",
        "\n",
        "        actuals = df.groupby('interval', observed=True)['returns'].sum() * 100\n",
        "\n",
        "        try:\n",
        "            pred = full_df[full_df['Ticker'] == ticker].set_index('Interval')\n",
        "            if 'Predicted Mean Return (%)' not in pred.columns:\n",
        "                print(f\"âŒ Missing predicted values for {ticker}\")\n",
        "                continue\n",
        "            pred['Realized Return (%)'] = actuals\n",
        "            pred['Abs Error'] = (pred['Predicted Mean Return (%)'] - pred['Realized Return (%)']).abs()\n",
        "            pred['Ticker'] = ticker\n",
        "            all_evals.append(pred.reset_index())\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Could not evaluate {ticker}: {e}\")\n",
        "\n",
        "    return pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()\n",
        "\n",
        "# âœ… User Input\n",
        "tickers = input(\"Enter tickers separated by commas: \").strip().upper().split(',')\n",
        "tickers = [t.strip() for t in tickers if t.strip()]\n",
        "date_input = input(\"Enter trading date (YYYY-MM-DD): \").strip()\n",
        "\n",
        "# âœ… Predictions path (from morning mode)\n",
        "pred_file = save_dir / f\"combined_predictions_{date_input}.csv\"\n",
        "\n",
        "if mode == 'afternoon' and pred_file.exists():\n",
        "    result_df = evaluate_actual_vs_predicted(pred_file, tickers, date_input)\n",
        "\n",
        "    if not result_df.empty:\n",
        "        # Save styled Excel report\n",
        "        excel_path = save_dir / f\"evaluated_predictions_{date_input}.xlsx\"\n",
        "\n",
        "        def color_val(val):\n",
        "            color = \"green\" if val > 0 else \"red\" if val < 0 else \"black\"\n",
        "            return f\"color: {color}\"\n",
        "\n",
        "        styled = result_df.style.format({\n",
        "            \"Predicted Mean Return (%)\": \"{:+.2f}\",\n",
        "            \"Realized Return (%)\": \"{:+.2f}\",\n",
        "            \"Abs Error\": \"{:.2f}\"\n",
        "        }).applymap(color_val, subset=[\"Predicted Mean Return (%)\", \"Realized Return (%)\"])\n",
        "\n",
        "        styled.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "        print(f\"âœ… Evaluation saved to Excel: {excel_path}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ No evaluations computed.\")\n",
        "else:\n",
        "    print(\"âŒ Predictions CSV not found or mode is not 'afternoon'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UP_S3d9P5qT",
        "outputId": "107cb151-4962-443f-bab4-2ff66fe51c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter tickers separated by commas: NEHC, HCTI, GNLN, CGTL, CVAC, GTI, SOAR, CGTL, RADX\n",
            "Enter trading date (YYYY-MM-DD): 2025-06-12\n",
            "âš ï¸ Could not evaluate NEHC: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate HCTI: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate GNLN: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate CGTL: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate CVAC: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate GTI: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate SOAR: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate CGTL: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ Could not evaluate RADX: \"None of ['Interval'] are in the columns\"\n",
            "âš ï¸ No evaluations computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # Afternoon Mode.2"
      ],
      "metadata": {
        "id": "ASUdXC-KfS0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… MODE TOGGLE\n",
        "mode = 'afternoon'  # Options: 'morning' or 'afternoon'\n",
        "\n",
        "# ðŸ“¦ Install dependencies\n",
        "!pip install pandas matplotlib seaborn scikit-learn xgboost openpyxl --quiet\n",
        "\n",
        "# ðŸ”§ Imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "\n",
        "# ðŸ—‚ï¸ Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = Path('/content/drive/MyDrive/stock_predictions')\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ðŸŽ¯ Polygon API\n",
        "API_KEY = 'H3nRWzRqnMqojU9y1gkbo1UqTbl2peqf'\n",
        "\n",
        "# ðŸ“ˆ Fetch minute-level data\n",
        "def fetch_minute_data(ticker, date):\n",
        "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/{date}/{date}\"\n",
        "    params = {\"adjusted\": \"true\", \"sort\": \"asc\", \"limit\": 50000, \"apiKey\": API_KEY}\n",
        "    r = requests.get(url, params=params)\n",
        "    if r.status_code != 200:\n",
        "        print(f\"\\u274c Error fetching data for {ticker}: {r.text}\")\n",
        "        return None\n",
        "    df = pd.DataFrame(r.json().get(\"results\", []))\n",
        "    if df.empty:\n",
        "        return None\n",
        "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df.rename(columns={\"o\": \"open\", \"h\": \"high\", \"l\": \"low\", \"c\": \"close\", \"v\": \"volume\"})\n",
        "    return df[['open', 'high', 'low', 'close', 'volume']]\n",
        "\n",
        "# ðŸ” Evaluate Predictions vs Actuals\n",
        "def evaluate_actual_vs_predicted(pred_path, tickers, date):\n",
        "    full_df = pd.read_csv(pred_path)\n",
        "    all_evals = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        df = fetch_minute_data(ticker, date)\n",
        "        if df is None:\n",
        "            continue\n",
        "\n",
        "        df = df.between_time(\"09:30\", \"12:00\").copy()\n",
        "        df['returns'] = df['close'].pct_change()\n",
        "\n",
        "        df['Interval'] = pd.cut(\n",
        "            df.index.hour * 60 + df.index.minute,\n",
        "            bins=[0, 600, 630, 660],\n",
        "            labels=['early (9:30â€“10:00)', 'mid (10:00â€“10:30)', 'late (10:30â€“11:00)']\n",
        "        )\n",
        "\n",
        "        actuals = df.groupby('Interval', observed=True)['returns'].sum() * 100\n",
        "\n",
        "        try:\n",
        "            # Ensure alignment by converting intervals to strings\n",
        "            actuals.index = actuals.index.astype(str)\n",
        "            pred = full_df[full_df['Ticker'] == ticker].copy()\n",
        "            pred['Interval'] = pred['Interval'].astype(str)\n",
        "            pred.set_index('Interval', inplace=True)\n",
        "\n",
        "            # Join and calculate error\n",
        "            pred = pred.join(actuals.rename(\"Realized Return (%)\"), how='left')\n",
        "            pred['Abs Error'] = (pred['Predicted Mean Return (%)'] - pred['Realized Return (%)']).abs()\n",
        "            pred['Ticker'] = ticker\n",
        "\n",
        "            all_evals.append(pred.reset_index())\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Could not evaluate {ticker}: {e}\")\n",
        "\n",
        "    return pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()\n",
        "\n",
        "# âœ… User Input\n",
        "tickers = input(\"Enter tickers separated by commas: \").strip().upper().split(',')\n",
        "tickers = [t.strip() for t in tickers if t.strip()]\n",
        "date_input = input(\"Enter trading date (YYYY-MM-DD): \").strip()\n",
        "\n",
        "# âœ… Predictions path (from morning mode)\n",
        "pred_file = save_dir / f\"combined_predictions_{date_input}.csv\"\n",
        "\n",
        "if mode == 'afternoon' and pred_file.exists():\n",
        "    result_df = evaluate_actual_vs_predicted(pred_file, tickers, date_input)\n",
        "\n",
        "    if not result_df.empty:\n",
        "        excel_path = save_dir / f\"evaluated_predictions_{date_input}.xlsx\"\n",
        "\n",
        "        def color_val(val):\n",
        "            color = \"green\" if val > 0 else \"red\" if val < 0 else \"black\"\n",
        "            return f\"color: {color}\"\n",
        "\n",
        "        styled = result_df.style.format({\n",
        "            \"Predicted Mean Return (%)\": \"{:+.2f}\",\n",
        "            \"Realized Return (%)\": \"{:+.2f}\",\n",
        "            \"Abs Error\": \"{:.2f}\"\n",
        "        }).applymap(color_val, subset=[\"Predicted Mean Return (%)\", \"Realized Return (%)\"])\n",
        "\n",
        "        styled.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "        print(f\"\\u2705 Evaluation saved to Excel: {excel_path}\")\n",
        "    else:\n",
        "        print(\"\\u26a0\\ufe0f No evaluations computed.\")\n",
        "else:\n",
        "    print(\"\\u274c Predictions CSV not found or mode is not 'afternoon'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfg9ogkzfZ8G",
        "outputId": "42c29044-bf1c-461b-917a-8b269096ecf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter tickers separated by commas: SLRX, VERV, INEO, SAFX, BGSF, XTIA, TDTH, RBNE\n",
            "Enter trading date (YYYY-MM-DD): 2025-06-17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-3985383034>:103: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
            "  }).applymap(color_val, subset=[\"Predicted Mean Return (%)\", \"Realized Return (%)\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Evaluation saved to Excel: /content/drive/MyDrive/stock_predictions/evaluated_predictions_2025-06-17.xlsx\n"
          ]
        }
      ]
    }
  ]
}